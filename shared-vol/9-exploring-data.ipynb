{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data\n",
    "![footer_logo_new](images/logo_new.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import StorageLevel\n",
    "from pyspark.sql import functions as F, SQLContext, SparkSession, Window\n",
    "from pyspark.sql.types import*\n",
    "from random import randint\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"explore-data\")\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.eventLog.enabled\", \"true\")\n",
    "         .config(\"spark.eventLog.dir\", \"/opt/workspace/history\")\n",
    "         .config(\"spark.speculation\", \"true\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate()\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meteo observations \n",
    "- Parquet format\n",
    "- partitioned by year (yyyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_data_file = \"data/meteo-data/parquet\"\n",
    "meteo_df = spark.read.parquet(meteo_data_file)\n",
    "meteo_df.printSchema()\n",
    "meteo_df.show(10, truncate=100)\n",
    "# be careful with `describe` operation on the large datasets, as it triggers statistical analysis job\n",
    "# meteo_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stations dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_meta_file = \"data/meteo-data/stations.csv\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('station_identifier', StringType(), True),\n",
    "    StructField('latitude', FloatType(), True),\n",
    "    StructField('longitude', FloatType(), True),\n",
    "    StructField('height_above_sea_level', FloatType(), True),\n",
    "    StructField('station_name', StringType(), True)\n",
    "])\n",
    "\n",
    "stations_df = (spark.read\n",
    "               .schema(schema)\n",
    "               .option(\"header\", \"false\")\n",
    "               .csv(stations_meta_file)\n",
    "              )\n",
    "\n",
    "# \n",
    "stations_df.printSchema()\n",
    "stations_df.show(10, truncate=100)\n",
    "stations_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation types dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_type_file = \"data/meteo-data/observation_type.csv\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('observation_type', StringType(), True),\n",
    "    StructField('description', StringType(), True)\n",
    "])\n",
    "\n",
    "observation_type_df = (spark.read\n",
    "               .schema(schema)\n",
    "               .option(\"header\", \"false\")\n",
    "               .csv(observation_type_file)\n",
    "              )\n",
    "observation_type_df.printSchema()\n",
    "observation_type_df.show(10, truncate=100)\n",
    "observation_type_df.describe().show(truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meteo flags dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_description_file = \"data/meteo-data/flag_description.csv\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('flag', StringType(), True),\n",
    "    StructField('flag_description', StringType(), True),\n",
    "    StructField('value', StringType(), True),\n",
    "    StructField('value_description', StringType(), True)\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "flag_description_df = (spark.read\n",
    "               .schema(schema)\n",
    "               .option(\"header\", \"false\")\n",
    "               .csv(flag_description_file)\n",
    "              )\n",
    "\n",
    "flag_description_df.printSchema()\n",
    "flag_description_df.show(10, truncate=100)\n",
    "flag_description_df.describe().show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
