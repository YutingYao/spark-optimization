{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://fonts.googleapis.com/css?family=Quicksand:300,700\" />\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://fonts.googleapis.com/css?family=Fira Code\" />\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"rise.css\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://fonts.googleapis.com/css?family=Quicksand:300,700\" />\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://fonts.googleapis.com/css?family=Fira Code\" />\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"rise.css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "ipytest.config(rewrite_asserts=True, magics=True)\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "__file__ = \"9-testing.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Testing in PySpark\n",
    "\n",
    "![footer_logo_new](images/logo_new.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Testing\n",
    "\n",
    "Testing is incredibly important when writing code and helps you verify that your code does what you expect. \n",
    "\n",
    "We won't focus on why you should test but rather how to write *unit tests*.\n",
    "\n",
    "Keep in mind that sometimes having good tests can reduce the amount of documentation you need to write."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Inline tests\n",
    "\n",
    "Tests can be written inline with your code like this:\n",
    "\n",
    "```python\n",
    "def coalesce_nan(a, b):\n",
    "    if (a and not np.isnan(a)):\n",
    "        return a\n",
    "    return b\n",
    "\n",
    "def test_coalesce():\n",
    "    assert coalesce_nan(None, 3) == 3\n",
    "    assert coalesce_nan(2, 3) == 2\n",
    "    assert coalesce_nan(np.nan, 3) == 3\n",
    "    assert coalesce_nan(np.nan, \"my\") == \"my\"\n",
    "```\n",
    "\n",
    "This has several advantages: no imports to manage, and if you use a tool such as `py.test`, it can recognize that it should only call the function with the `test_` prefix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tests in a separate directory\n",
    "\n",
    "Alternatively, when writing a Python package, you could have the following directory structure (for example)\n",
    "\n",
    "```sh\n",
    "setup.py\n",
    "conftest.py\n",
    "my_module/\n",
    "    __init__.py\n",
    "    app.py\n",
    "    helper.py\n",
    "tests/\n",
    "    helper_tests.py\n",
    "docs/\n",
    "    ...\n",
    "```\n",
    "\n",
    "Using `pytest` (`pip install pytest`) you could run the tests by typing `pytest` from the command line. The framework expects tests to be located in `tests/`, and assumes that the methods to be tested should begin with `test_`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Testing in PySpark\n",
    "\n",
    "To test your PySpark code, you need to put in some extra effort to setup a Spark instance for your tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Setting up Spark \n",
    "\n",
    "In `pytest`, we can setup a Spark instance by defining a fixture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture(scope=\"session\")\n",
    "def spark():\n",
    "    \"\"\"Returns a Spark instance for testing.\"\"\"\n",
    "    return ( \n",
    "        pyspark.sql.SparkSession.builder\n",
    "        .master(\"local[2]\") \n",
    "        .getOrCreate()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Once defined, fixtures can be passed to tests by using an input argument with the same name as the fixture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def test_example(spark):\n",
    "    \"\"\"Example test using the Spark fixture.\"\"\"\n",
    "         \n",
    "    data = pd.DataFrame({\n",
    "        \"a\": [1, 2, 3],\n",
    "        \"b\": [\"a\", \"b\", None]\n",
    "    })\n",
    "    example_df = spark.createDataFrame(data)\n",
    "    \n",
    "    assert example_df.count() == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For more information on pytest fixtures, see: https://docs.pytest.org/en/latest/fixture.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Test datasets\n",
    "\n",
    "Fixtures can also be used to define reusable test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "@pytest.fixture()\n",
    "def example_df(spark):\n",
    "    \"\"\"Example dataframe.\"\"\"\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        \"a\": [1, 2, 3],\n",
    "        \"b\": [\"a\", \"b\", None]\n",
    "    })\n",
    "    \n",
    "    return spark.createDataFrame(data)\n",
    "\n",
    "\n",
    "def test_example_fixture(example_df):\n",
    "    \"\"\"Example test using a test dataset from a fixture.\"\"\"\n",
    "    assert example_df.count() == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Of course you can also read a test dataset from a static input file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "import os\n",
    "\n",
    "@pytest.fixture(scope=\"session\")\n",
    "def airline_df(spark):\n",
    "    \"\"\"Rather large static dataset containing airline data.\"\"\"\n",
    "    data_path = os.path.join(DATA_DIR, 'airlines.parquet')\n",
    "    return spark.read.parquet(data_path)\n",
    "\n",
    "\n",
    "def test_example_fixture_heroes(airline_df):\n",
    "    assert airline_df.count() > 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How/what to test?\n",
    "\n",
    "In general, you should aim to write tests that (at the very least) cover the parts of your code that define your computations.\n",
    "\n",
    "You can make your code relatively easy to test by decomposing it into concise functions that take an input dataframe and return an output dataframe.\n",
    "\n",
    "This allows you to pass an example (test) dataframe to the function and verify the result(s). \n",
    "\n",
    "Try to structure your test dataframe(s) to test different edge cases in your function (such as null handling, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise - Testing\n",
    "\n",
    "1. Load the heroes dataset and write a function that filters the dataset for a given role:\n",
    "\n",
    "```python\n",
    "def filter_for_role(heroes_df, role):\n",
    "    ...\n",
    "```\n",
    "\n",
    "2. Write a unit test that applies your function for the 'Warrior' role and checks if the number of returned rows is what you would expect. Try to use a fixture for passing the test dataset to your unit test.\n",
    "\n",
    "3. Write a function that counts the number of occurrences of each role in a given dataset:\n",
    "\n",
    "``` python\n",
    "def count_roles(heroes_df):\n",
    "    ...\n",
    "```\n",
    "4. Write a unit test that checks the result of the `count_roles` function on our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%load ../answers/02_testing.py"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
