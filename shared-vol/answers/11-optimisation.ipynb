{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "### possible solution \n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql import functions as F, SQLContext, SparkSession, Window\n",
    "from pyspark.sql.types import*\n",
    "from random import randint\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"workshop-spark-optimisation\")\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.eventLog.enabled\", \"true\")\n",
    "         .config(\"spark.eventLog.dir\", \"/opt/workspace/history\")\n",
    "         .config(\"spark.executor.cores\", 2)\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate()\n",
    "         )\n",
    "\n",
    "meteo_data_file = \"/opt/workspace/data/meteo-data/parquet\"\n",
    "meteo_df = spark.read.parquet(meteo_data_file)\n",
    "\n",
    "stations_meta_file = \"/opt/workspace/data/meteo-data/stations.csv\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('station_identifier', StringType(), True),\n",
    "    StructField('latitude', FloatType(), True),\n",
    "    StructField('longitude', FloatType(), True),\n",
    "    StructField('height_above_sea_level', FloatType(), True),\n",
    "    StructField('station_name', StringType(), True)\n",
    "])\n",
    "\n",
    "stations_df = spark.read.schema(schema).option(\"header\", \"false\").csv(stations_meta_file)\n",
    "\n",
    "observation_type_file = \"/opt/workspace/data/meteo-data/observation_type.csv\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('observation_type', StringType(), True),\n",
    "    StructField('description', StringType(), True)\n",
    "])\n",
    "\n",
    "observation_type_df = spark.read.schema(schema).option(\"header\", \"false\").csv(observation_type_file)\n",
    "\n",
    "\n",
    "res = (\n",
    "    meteo_df\n",
    "    .where(\"yyyy == 2010 or yyyy == 2020\")\n",
    "    .where(\"yyyy > 2000\")\n",
    "    .join(stations_df, \"station_identifier\", \"left\")\n",
    "    .join(observation_type_df, \"observation_type\", \"left\")\n",
    "    .select( \"observation_type\",\"description\",\"observation_value\", \"latitude\")\n",
    "    .withColumn(\"station_zone\", \n",
    "                F.when((F.col(\"latitude\") > \"-20\")&(F.col(\"latitude\") < \"20\") , F.lit(\"equator\"))\n",
    "               .when(((F.col(\"latitude\")>=\"20\")&(F.col(\"latitude\") <\"30\"))|((F.col(\"latitude\") <=\"-20\")&(F.col(\"latitude\")>\"-30\")), F.lit(\"tropics\"))\n",
    "               .when(((F.col(\"latitude\")>=\"30\")&(F.col(\"latitude\") <\"40\"))|((F.col(\"latitude\") <=\"-30\")&(F.col(\"latitude\")>\"-40\")), F.lit(\"subtropics\"))\n",
    "               .when(((F.col(\"latitude\")>=\"40\")&(F.col(\"latitude\") <\"50\"))|((F.col(\"latitude\") <=\"-40\")&(F.col(\"latitude\")>\"-50\")), F.lit(\"warm_temperate\"))\n",
    "               .when(((F.col(\"latitude\")>=\"50\")&(F.col(\"latitude\") <\"60\"))|((F.col(\"latitude\") <=\"-50\")&(F.col(\"latitude\")>\"-60\")), F.lit(\"boreal\"))\n",
    "               .when(((F.col(\"latitude\")>=\"60\")&(F.col(\"latitude\") <\"70\"))|((F.col(\"latitude\") <=\"-60\")&(F.col(\"latitude\")>\"-70\")), F.lit(\"tundra\"))\n",
    "               .otherwise(F.lit(\"ice_cap\"))\n",
    "    )\n",
    "    .drop(\"latitude\")\n",
    "    .coalesce(10)\n",
    "    .write.format(\"parquet\").mode(\"overwrite\").save(\"res.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121754216"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"res.parquet\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
